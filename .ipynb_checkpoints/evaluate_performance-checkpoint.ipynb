{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stock-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-coating",
   "metadata": {},
   "source": [
    "# Import and Process Classification Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-subsection",
   "metadata": {},
   "source": [
    "## Inter-subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "occupational-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict = {}\n",
    "for file in os.listdir('./outputs/classifictaion/inter-subject'):\n",
    "    infile = open('./outputs/classifictaion/inter-subject/' + file, 'rb')\n",
    "    resultsDict['{}'.format(file)] = pickle.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interim-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for FrequencyAll_KNN_128.pickle is: 0.828149474155292.\n",
      "Test accuracy for FrequencyAll_KNN_320.pickle is: 0.8985915492957747.\n",
      "Test accuracy for FrequencyAll_RandomForest_128.pickle is: 0.8543298277019468.\n",
      "Test accuracy for FrequencyAll_RandomForest_320.pickle is: 0.9256338028169014.\n",
      "Test accuracy for FrequencyAll_SVC_128.pickle is: 0.8784963078988588.\n",
      "Test accuracy for FrequencyAll_SVC_320.pickle is: 0.948169014084507.\n",
      "Test accuracy for TimeFrequency_KNN_128.pickle is: 0.9093756992615798.\n",
      "Test accuracy for TimeFrequency_KNN_320.pickle is: 0.9622535211267605.\n",
      "Test accuracy for TimeFrequency_RandomForest_128.pickle is: 0.8916983665249496.\n",
      "Test accuracy for TimeFrequency_RandomForest_320.pickle is: 0.9656338028169014.\n",
      "Test accuracy for TimeFrequency_SVC_128.pickle is: 0.9178787200716044.\n",
      "Test accuracy for TimeFrequency_SVC_320.pickle is: 0.967887323943662.\n",
      "Test accuracy for Time_KNN_128.pickle is: 0.8498545535914075.\n",
      "Test accuracy for Time_KNN_320.pickle is: 0.9053521126760563.\n",
      "Test accuracy for Time_RandomForest_128.pickle is: 0.8496307898858805.\n",
      "Test accuracy for Time_RandomForest_320.pickle is: 0.9183098591549296.\n",
      "Test accuracy for Time_SVC_128.pickle is: 0.8668605952114568.\n",
      "Test accuracy for Time_SVC_320.pickle is: 0.9025352112676056.\n"
     ]
    }
   ],
   "source": [
    "for key in resultsDict.keys():\n",
    "    Y_true_pred = resultsDict[key]['TruePredY']\n",
    "    best_accuracy = accuracy_score(Y_true_pred.values[:,0], Y_true_pred.values[:,1])\n",
    "    print('Test accuracy for {} is: {}.'.format(key, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-lafayette",
   "metadata": {},
   "source": [
    "### Table of Metrics for a Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recognized-joshua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>electricPanel</th>\n",
       "      <th>hoist</th>\n",
       "      <th>ladder</th>\n",
       "      <th>lift</th>\n",
       "      <th>overhead</th>\n",
       "      <th>push</th>\n",
       "      <th>sit</th>\n",
       "      <th>stand</th>\n",
       "      <th>type</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>360</td>\n",
       "      <td>441</td>\n",
       "      <td>862</td>\n",
       "      <td>516</td>\n",
       "      <td>360</td>\n",
       "      <td>493</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          electricPanel hoist ladder  lift overhead  push   sit stand  type  \\\n",
       "precision          0.83  0.96    0.7  0.76     0.91  0.85  0.81  0.89  0.86   \n",
       "recall             0.87  0.69   0.82  0.84     0.69  0.87  0.94  0.87  0.76   \n",
       "f1-score           0.85   0.8   0.76   0.8     0.78  0.86  0.87  0.88  0.81   \n",
       "support             360   441    862   516      360   493   360   360   360   \n",
       "\n",
       "           walk  \n",
       "precision   1.0  \n",
       "recall     0.96  \n",
       "f1-score   0.98  \n",
       "support     357  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result = resultsDict['FrequencyAll_KNN_128']['TruePredY']\n",
    "sample_reports = classification_report(sample_result['True'], sample_result['Predicted'], digits=3, output_dict=True)\n",
    "sample_reports_df = pd.DataFrame(sample_reports)\n",
    "sample_reports_df = sample_reports_df.round(decimals=2)\n",
    "sample_reports_df.loc['support'] = sample_reports_df.loc['support'].astype(int).astype(str)\n",
    "sample_reports_df = sample_reports_df.drop(columns=['accuracy', 'macro avg', 'weighted avg'])\n",
    "sample_reports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-buying",
   "metadata": {},
   "source": [
    "### Create Table of Metrics for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colonial-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "allReports_df = pd.DataFrame(columns=['electricPanel', 'hoist', 'ladder', 'lift', 'overhead', 'push', 'sit', 'stand', 'type', 'walk'])\n",
    "for key in resultsDict.keys():\n",
    "    truePredY = resultsDict[key]['TruePredY']\n",
    "    reports = classification_report(truePredY['True'], truePredY['Predicted'], output_dict=True)\n",
    "    reports_df = pd.DataFrame(reports)\n",
    "    reports_df = reports_df.round(decimals=2)\n",
    "    reports_df.loc['support'] = reports_df.loc['support'].astype(int).astype(str)\n",
    "    reports_df = reports_df.drop(columns=['accuracy', 'macro avg', 'weighted avg'])\n",
    "    allReports_df = pd.concat([allReports_df, reports_df], axis=0)\n",
    "allReports_df.to_csv('./report_interSubject.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-celebration",
   "metadata": {},
   "source": [
    "## Intra-subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opened-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir('./outputs/classification/intra-subject')\n",
    "group_dict = {}\n",
    "for file_name in file_names:\n",
    "    key  = file_name.split('_Subject', 1)[0]\n",
    "    if key not in group_dict.keys():\n",
    "        group_dict[key] = [file_name]\n",
    "    else:\n",
    "        group_dict[key].append(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-difficulty",
   "metadata": {},
   "source": [
    "### Mean Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results_dict = {}\n",
    "for key in group_dict.keys():\n",
    "    report_list = []\n",
    "    for file in group_dict[key]:\n",
    "        with open('./outputs/classification/intra-subject/'+file, 'rb') as infile:\n",
    "            class_dict = pickle.load(infile)\n",
    "            sample_result = class_dict['TruePredY']\n",
    "            sample_reports = classification_report(sample_result['True'], sample_result['Predicted'], output_dict=True)\n",
    "            sample_reports_df = pd.DataFrame(sample_reports).drop(columns=['macro avg', 'weighted avg'], index='support')\n",
    "            report_list.append(sample_reports_df)\n",
    "    mean_results_dict[key] = pd.concat(report_list).reset_index().groupby('index').mean().round(decimals=2).reset_index()\n",
    "pd.concat(list(mean_results_dict.values())).to_csv('./report_intraSubject.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
